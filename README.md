# Kafka Java Project - Gestion et Analyse des DonnÃ©es Massives

## Introduction

Ce projet s'inscrit dans le cadre du **Master 2 Bases de DonnÃ©es et Intelligence Artificielle**, dans le module de *
*Gestion et analyse des DonnÃ©es Massives**. Il vise Ã  expÃ©rimenter l'utilisation d'**Apache Kafka** pour la gestion de
flux de donnÃ©es en temps rÃ©el et Ã  comparer ses fonctionnalitÃ©s avec **JMS**.

## ğŸ“Œ Objectifs du projet

1. **Exercice 2 : Clients Kafka en Java**
    - ImplÃ©menter un **producteur Kafka** en Java.
    - Mettre en place un **consommateur Kafka** et tester la rÃ©ception des messages.
    - ExpÃ©rimenter la **rÃ©partition des messages** sur plusieurs partitions et groupes de consommateurs.
    - Comparer les mÃ©canismes de consommation de Kafka avec ceux de **JMS**.

2. **Exercice 3 : Stream Processing avec Kafka**
    - Construire une **architecture Kafka Streams** pour traiter des flux de donnÃ©es issues de capteurs de tempÃ©rature.
    - DÃ©velopper un **producteur multi-source** qui envoie pÃ©riodiquement des relevÃ©s de tempÃ©rature.
    - Mettre en place un **traitement en temps rÃ©el** pour calculer des moyennes et gÃ©nÃ©rer des alertes en cas de
      dÃ©passement de seuils.

---

## ğŸ—ï¸ Architecture du projet

Le projet repose sur plusieurs composants :

- **Zookeeper** : Coordonne le cluster Kafka et gÃ¨re les mÃ©tadonnÃ©es.
- **Kafka Brokers** : Stockent et distribuent les messages aux consommateurs.
- **Producteurs Java** : Envoient des messages Ã  Kafka.
- **Consommateurs Java** : RÃ©cupÃ¨rent et traitent les messages depuis Kafka.
- **Kafka Streams** : Traite les flux en temps rÃ©el et gÃ©nÃ¨re des analyses.

## ğŸ› ï¸ Installation et ExÃ©cution

### ğŸ“Œ PrÃ©requis

- **Java 17+**
- **Docker** et **Docker Compose**

### ğŸ”¹ Installation et ExÃ©cution

1. Cloner le dÃ©pÃ´t GitHub :

```bash
git clone https://github.com/Maxime-Cllt/Kafka.git
cd Kafka
```

2. Lancer les services Kafka et Zookeeper :

```bash
docker-compose up
```

3. Compiler et exÃ©cuter les classes Java pour l'initialisation des topics :

```bash
gradlew clean build
gradlew runMain
```

### ğŸ“¦ Exercice 2 : Clients Kafka en Java

```bash
gradlew runProducer
gradlew runConsumer
```

### ğŸ“¦ Exercice 3 : Stream Processing avec Kafka

```bash
gradlew runEx3Consumer
gradlew runEx3Producteur
```


## ğŸ“Š RÃ©sultats attendus

- VÃ©rification de la bonne transmission des messages entre producteurs et consommateurs.
- Mesure des performances en fonction du nombre de partitions et de consommateurs.
- Analyse du traitement en temps rÃ©el via Kafka Streams.
